{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Day 4-5 Baseline Model Training\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Overview\n",
    "\n",
    "Train and evaluate regression models for music emotion recognition.\n",
    "\n",
    "### ðŸŽ¯ Objectives\n",
    "- Predict Valence and Arousal using 133-dimensional audio features\n",
    "- Compare different models and feature selection strategies\n",
    "- Analyze feature importance\n",
    "\n",
    "### ðŸ“Š Data\n",
    "- **Input**: `deam_features_all.csv` (1,802 songs Ã— 133 features)\n",
    "- **Targets**: Valence (pleasantness), Arousal (activation)\n",
    "- **Range**: 1-9 continuous values\n",
    "\n",
    "### ðŸ¤– Models\n",
    "1. **Linear Regression** (baseline) - with feature selection\n",
    "2. **Random Forest** (advanced) - with all features\n",
    "\n",
    "### ðŸ“ˆ Evaluation Metrics\n",
    "- **MSE** (Mean Squared Error) - lower is better\n",
    "- **RMSE** (Root MSE) - same unit as target\n",
    "- **RÂ²** (Coefficient of Determination) - 0-1, higher is better\n",
    "- **MAE** (Mean Absolute Error) - average error\n",
    "- **NRMSE** (Normalized RMSE) - RMSE / range\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"Random seed: {RANDOM_STATE}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set paths\n",
    "BASE_DIR = Path('..')\n",
    "DATA_DIR = BASE_DIR / 'data' / 'DEAM' / 'processed'\n",
    "OUTPUT_DIR = BASE_DIR / 'models'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load feature data\n",
    "df = pd.read_csv(DATA_DIR / 'deam_features_all.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Data loaded successfully\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Number of songs: {len(df)}\")\n",
    "print(f\"Total features: {len(df.columns) - 3} (excluding song_id, valence, arousal)\")\n",
    "\n",
    "# Check data\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(df[['valence', 'arousal']].describe())\n",
    "\n",
    "# Display first rows\n",
    "print(f\"\\nData preview:\")\n",
    "df.head(3)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection Strategy\n",
    "\n",
    "Based on Day 3 correlation analysis, we implement two strategies:\n",
    "\n",
    "### Strategy Comparison\n",
    "\n",
    "| Strategy | Model | # Features | Reason |\n",
    "|----------|-------|------------|--------|\n",
    "| **Strategy A: Feature Selection** | Linear Regression | ~129 | Reduce multicollinearity |\n",
    "| **Strategy B: Keep All** | Random Forest | 133 | Tree models handle multicollinearity |\n",
    "\n",
    "### Selection Rules (Strategy A)\n",
    "\n",
    "1. âœ… **Keep**: `mfcc_mean_0` (most important feature r=0.59)\n",
    "2. âŒ **Remove**: `spectral_rolloff`, `spectral_bandwidth` (redundant with centroid r>0.89)\n",
    "3. âœ… **Keep**: `spectral_centroid` (representative of spectral group)\n",
    "4. âœ… **Keep**: All Chroma and Spectral Contrast features\n",
    "5. âœ… **Keep**: Rhythm features (`tempo`, `beat_strength`)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Separate features and targets\n",
    "X_all = df.drop(['song_id', 'valence', 'arousal'], axis=1)\n",
    "y_valence = df['valence']\n",
    "y_arousal = df['arousal']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Feature Selection\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Strategy A: Feature selection (for linear regression)\n",
    "# Remove highly redundant features\n",
    "features_to_remove = [\n",
    "    'spectral_rolloff_mean', 'spectral_rolloff_std',      # Redundant with centroid (r=0.98)\n",
    "    'spectral_bandwidth_mean', 'spectral_bandwidth_std',  # Redundant with centroid (r=0.89)\n",
    "]\n",
    "\n",
    "# Create selected feature set\n",
    "X_selected = X_all.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"\\nStrategy A - Feature Selection (for Linear Regression):\")\n",
    "print(f\"  â€¢ Original features: {X_all.shape[1]}\")\n",
    "print(f\"  â€¢ Removed features: {len(features_to_remove)}\")\n",
    "print(f\"  â€¢ Retained features: {X_selected.shape[1]}\")\n",
    "print(f\"  â€¢ Features removed: {features_to_remove}\")\n",
    "\n",
    "print(f\"\\nStrategy B - Keep All (for Random Forest):\")\n",
    "print(f\"  â€¢ Features: {X_all.shape[1]}\")\n",
    "print(f\"  â€¢ Strategy: Let model handle multicollinearity\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_selected = X_selected.columns.tolist()\n",
    "feature_names_all = X_all.columns.tolist()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting\n",
    "\n",
    "### Split Strategy\n",
    "- **Training set**: 70% (~1,261 songs)\n",
    "- **Validation set**: 15% (~271 songs)\n",
    "- **Test set**: 15% (~270 songs)\n",
    "\n",
    "### Why three sets?\n",
    "- **Training set**: For model learning\n",
    "- **Validation set**: For hyperparameter tuning and model selection\n",
    "- **Test set**: For final evaluation (model never sees this)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def split_data(X, y_val, y_aro, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into train/validation/test sets\n",
    "    \n",
    "    Parameters:\n",
    "        X: Feature matrix\n",
    "        y_val: Valence target\n",
    "        y_aro: Arousal target\n",
    "        test_size: Test set proportion\n",
    "        val_size: Validation set proportion (relative to remaining data)\n",
    "        random_state: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all split data\n",
    "    \"\"\"\n",
    "    # First split: separate test set\n",
    "    X_temp, X_test, y_val_temp, y_val_test, y_aro_temp, y_aro_test = train_test_split(\n",
    "        X, y_val, y_aro, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: separate validation set from remaining data\n",
    "    X_train, X_val, y_val_train, y_val_val, y_aro_train, y_aro_val = train_test_split(\n",
    "        X_temp, y_val_temp, y_aro_temp, test_size=val_size/(1-test_size), random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train, 'X_val': X_val, 'X_test': X_test,\n",
    "        'y_val_train': y_val_train, 'y_val_val': y_val_val, 'y_val_test': y_val_test,\n",
    "        'y_aro_train': y_aro_train, 'y_aro_val': y_aro_val, 'y_aro_test': y_aro_test\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Data Splitting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Strategy A: Selected features\n",
    "data_selected = split_data(X_selected, y_valence, y_arousal)\n",
    "\n",
    "# Strategy B: All features\n",
    "data_all = split_data(X_all, y_valence, y_arousal)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Training: {len(data_selected['X_train'])} songs ({len(data_selected['X_train'])/len(df)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(data_selected['X_val'])} songs ({len(data_selected['X_val'])/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test: {len(data_selected['X_test'])} songs ({len(data_selected['X_test'])/len(df)*100:.1f}%)\")\n",
    "print(f\"  Total: {len(df)} songs\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Standardization\n",
    "\n",
    "### Why standardization?\n",
    "- Different features have different scales (e.g., tempo ~120, mfcc_mean_0 ~-150)\n",
    "- Linear regression is scale-sensitive\n",
    "- After standardization, all features have mean=0, std=1\n",
    "\n",
    "### âš ï¸ Important Rule\n",
    "- **Only fit Scaler on training set** - avoid data leakage\n",
    "- **Use same parameters to transform validation and test sets**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def standardize_features(data_dict):\n",
    "    \"\"\"\n",
    "    Standardize features (fit only on training set)\n",
    "    \n",
    "    Parameters:\n",
    "        data_dict: Dictionary containing X_train, X_val, X_test\n",
    "    \n",
    "    Returns:\n",
    "        Standardized data dictionary and scaler object\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit only on training set\n",
    "    scaler.fit(data_dict['X_train'])\n",
    "    \n",
    "    # Transform all sets\n",
    "    data_dict['X_train_scaled'] = scaler.transform(data_dict['X_train'])\n",
    "    data_dict['X_val_scaled'] = scaler.transform(data_dict['X_val'])\n",
    "    data_dict['X_test_scaled'] = scaler.transform(data_dict['X_test'])\n",
    "    \n",
    "    return data_dict, scaler\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Feature Standardization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Standardize both strategies\n",
    "data_selected, scaler_selected = standardize_features(data_selected)\n",
    "data_all, scaler_all = standardize_features(data_all)\n",
    "\n",
    "# Verify standardization\n",
    "print(f\"\\nBefore standardization (Training set):\") \n",
    "print(f\"  Mean: {data_selected['X_train'].mean(axis=0)[:3].values}...\")\n",
    "print(f\"  Std: {data_selected['X_train'].std(axis=0)[:3].values}...\")\n",
    "\n",
    "print(f\"\\nAfter standardization (Training set):\")\n",
    "print(f\"  Mean: {data_selected['X_train_scaled'].mean(axis=0)[:3]}...\")\n",
    "print(f\"  Std: {data_selected['X_train_scaled'].std(axis=0)[:3]}...\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Model | Feature Strategy | Advantages | Disadvantages |\n",
    "|-------|------------------|------------|---------------|\n",
    "| **Linear Regression** | Selected features | Simple, interpretable | Only linear relationships |\n",
    "| **Random Forest** | All features | Captures nonlinearity, feature importance | Black box, slower |\n",
    "\n",
    "### Training Strategy\n",
    "- Train separate models for Valence and Arousal\n",
    "- Fit on training set\n",
    "- Evaluate on validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Linear Regression (Baseline Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Training Linear Regression models\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create models\n",
    "lr_valence = LinearRegression()\n",
    "lr_arousal = LinearRegression()\n",
    "\n",
    "# Train Valence model\n",
    "lr_valence.fit(data_selected['X_train_scaled'], data_selected['y_val_train'])\n",
    "\n",
    "# Train Arousal model\n",
    "lr_arousal.fit(data_selected['X_train_scaled'], data_selected['y_aro_train'])\n",
    "\n",
    "# Predictions\n",
    "lr_val_train_pred = lr_valence.predict(data_selected['X_train_scaled'])\n",
    "lr_val_val_pred = lr_valence.predict(data_selected['X_val_scaled'])\n",
    "\n",
    "lr_aro_train_pred = lr_arousal.predict(data_selected['X_train_scaled'])\n",
    "lr_aro_val_pred = lr_arousal.predict(data_selected['X_val_scaled'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest (Advanced Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Training Random Forest models\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create models\n",
    "rf_valence = RandomForestRegressor(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=20,          # Maximum depth\n",
    "    min_samples_split=5,   # Minimum samples to split\n",
    "    min_samples_leaf=2,    # Minimum samples per leaf\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "rf_arousal = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train Valence model\n",
    "rf_valence.fit(data_all['X_train_scaled'], data_all['y_val_train'])\n",
    "\n",
    "# Train Arousal model\n",
    "rf_arousal.fit(data_all['X_train_scaled'], data_all['y_aro_train'])\n",
    "\n",
    "# Predictions\n",
    "rf_val_train_pred = rf_valence.predict(data_all['X_train_scaled'])\n",
    "rf_val_val_pred = rf_valence.predict(data_all['X_val_scaled'])\n",
    "\n",
    "rf_aro_train_pred = rf_arousal.predict(data_all['X_train_scaled'])\n",
    "rf_aro_val_pred = rf_arousal.predict(data_all['X_val_scaled'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define evaluation functions\n",
    "\n",
    "# Define data ranges (for NRMSE calculation)\n",
    "VALENCE_RANGE = 8.4 - 1.6  # 6.8\n",
    "AROUSAL_RANGE = 8.1 - 1.6  # 6.5\n",
    "\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\", target_range=None):\n",
    "    \"\"\"\n",
    "    Calculate regression model evaluation metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted values\n",
    "    dataset_name : str\n",
    "        Dataset name (Train/Validation/Test)\n",
    "    target_range : float, optional\n",
    "        Target variable range (max - min), for NRMSE calculation\n",
    "        If None, NRMSE is not calculated\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing MSE, RMSE, MAE, RÂ², NRMSE\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ²': r2\n",
    "    }\n",
    "    \n",
    "    # Calculate NRMSE (Normalized RMSE)\n",
    "    if target_range is not None and target_range > 0:\n",
    "        nrmse = rmse / target_range\n",
    "        result['NRMSE'] = nrmse\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_evaluation(results_dict, title=\"\"):\n",
    "    \"\"\"Print evaluation results\"\"\"\n",
    "    if isinstance(results_dict, dict):\n",
    "        results_dict = [results_dict]\n",
    "        \n",
    "    if title:\n",
    "        print(f\"\\n{title}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Check if NRMSE is included\n",
    "    has_nrmse = 'NRMSE' in results_dict[0] if results_dict else False\n",
    "    \n",
    "    if has_nrmse:\n",
    "        print(f\"{'Dataset':<15} {'MSE':>10} {'RMSE':>10} {'MAE':>10} {'RÂ²':>10} {'NRMSE':>10}\")\n",
    "    else:\n",
    "        print(f\"{'Dataset':<15} {'MSE':>10} {'RMSE':>10} {'MAE':>10} {'RÂ²':>10}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for result in results_dict:\n",
    "        if has_nrmse:\n",
    "            print(f\"{result['dataset']:<15} \"\n",
    "                  f\"{result['MSE']:>10.4f} \"\n",
    "                  f\"{result['RMSE']:>10.4f} \"\n",
    "                  f\"{result['MAE']:>10.4f} \"\n",
    "                  f\"{result['RÂ²']:>10.4f} \"\n",
    "                  f\"{result['NRMSE']:>10.4f}\")\n",
    "        else:\n",
    "            print(f\"{result['dataset']:<15} \"\n",
    "                  f\"{result['MSE']:>10.4f} \"\n",
    "                  f\"{result['RMSE']:>10.4f} \"\n",
    "                  f\"{result['MAE']:>10.4f} \"\n",
    "                  f\"{result['RÂ²']:>10.4f}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"Valence range: 1.6 - 8.4 (Î” = {VALENCE_RANGE:.1f})\")\n",
    "print(f\"Arousal range: 1.6 - 8.1 (Î” = {AROUSAL_RANGE:.1f})\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## 6.3 Additional Models (Ridge / Lasso / ElasticNet / SVR)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Training additional models (using selected & standardized features)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use same features and standardization as linear regression (data_selected)\n",
    "Xtr = data_selected['X_train_scaled']\n",
    "Xval = data_selected['X_val_scaled']\n",
    "\n",
    "# Valence models\n",
    "ridge_val = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "ridge_val.fit(Xtr, data_selected['y_val_train'])\n",
    "ridge_val_train_pred = ridge_val.predict(Xtr)\n",
    "ridge_val_val_pred = ridge_val.predict(Xval)\n",
    "\n",
    "lasso_val = Lasso(alpha=0.001, max_iter=10000, random_state=RANDOM_STATE)\n",
    "lasso_val.fit(Xtr, data_selected['y_val_train'])\n",
    "lasso_val_train_pred = lasso_val.predict(Xtr)\n",
    "lasso_val_val_pred = lasso_val.predict(Xval)\n",
    "\n",
    "enet_val = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000, random_state=RANDOM_STATE)\n",
    "enet_val.fit(Xtr, data_selected['y_val_train'])\n",
    "enet_val_train_pred = enet_val.predict(Xtr)\n",
    "enet_val_val_pred = enet_val.predict(Xval)\n",
    "\n",
    "svr_val = SVR(kernel='rbf', C=10.0, epsilon=0.1, gamma='scale')\n",
    "svr_val.fit(Xtr, data_selected['y_val_train'])\n",
    "svr_val_train_pred = svr_val.predict(Xtr)\n",
    "svr_val_val_pred = svr_val.predict(Xval)\n",
    "\n",
    "ridge_val_results = [\n",
    "    evaluate_model(data_selected['y_val_train'], ridge_val_train_pred, \"Train\", target_range=VALENCE_RANGE),\n",
    "    evaluate_model(data_selected['y_val_val'], ridge_val_val_pred, \"Validation\", target_range=VALENCE_RANGE)\n",
    "]\n",
    "lasso_val_results = [\n",
    "    evaluate_model(data_selected['y_val_train'], lasso_val_train_pred, \"Train\", target_range=VALENCE_RANGE),\n",
    "    evaluate_model(data_selected['y_val_val'], lasso_val_val_pred, \"Validation\", target_range=VALENCE_RANGE)\n",
    "]\n",
    "enet_val_results = [\n",
    "    evaluate_model(data_selected['y_val_train'], enet_val_train_pred, \"Train\", target_range=VALENCE_RANGE),\n",
    "    evaluate_model(data_selected['y_val_val'], enet_val_val_pred, \"Validation\", target_range=VALENCE_RANGE)\n",
    "]\n",
    "svr_val_results = [\n",
    "    evaluate_model(data_selected['y_val_train'], svr_val_train_pred, \"Train\", target_range=VALENCE_RANGE),\n",
    "    evaluate_model(data_selected['y_val_val'], svr_val_val_pred, \"Validation\", target_range=VALENCE_RANGE)\n",
    "]\n",
    "\n",
    "print_evaluation(ridge_val_results, \"Ridge - Valence\")\n",
    "print_evaluation(lasso_val_results, \"Lasso - Valence\")\n",
    "print_evaluation(enet_val_results,  \"ElasticNet - Valence\")\n",
    "print_evaluation(svr_val_results,   \"SVR (RBF) - Valence\")\n",
    "\n",
    "# Arousal models\n",
    "ridge_aro = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "ridge_aro.fit(Xtr, data_selected['y_aro_train'])\n",
    "ridge_aro_train_pred = ridge_aro.predict(Xtr)\n",
    "ridge_aro_val_pred = ridge_aro.predict(Xval)\n",
    "\n",
    "lasso_aro = Lasso(alpha=0.001, max_iter=10000, random_state=RANDOM_STATE)\n",
    "lasso_aro.fit(Xtr, data_selected['y_aro_train'])\n",
    "lasso_aro_train_pred = lasso_aro.predict(Xtr)\n",
    "lasso_aro_val_pred = lasso_aro.predict(Xval)\n",
    "\n",
    "enet_aro = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000, random_state=RANDOM_STATE)\n",
    "enet_aro.fit(Xtr, data_selected['y_aro_train'])\n",
    "enet_aro_train_pred = enet_aro.predict(Xtr)\n",
    "enet_aro_val_pred = enet_aro.predict(Xval)\n",
    "\n",
    "svr_aro = SVR(kernel='rbf', C=10.0, epsilon=0.1, gamma='scale')\n",
    "svr_aro.fit(Xtr, data_selected['y_aro_train'])\n",
    "svr_aro_train_pred = svr_aro.predict(Xtr)\n",
    "svr_aro_val_pred = svr_aro.predict(Xval)\n",
    "\n",
    "ridge_aro_results = [\n",
    "    evaluate_model(data_selected['y_aro_train'], ridge_aro_train_pred, \"Train\", target_range=AROUSAL_RANGE),\n",
    "    evaluate_model(data_selected['y_aro_val'], ridge_aro_val_pred, \"Validation\", target_range=AROUSAL_RANGE)\n",
    "]\n",
    "lasso_aro_results = [\n",
    "    evaluate_model(data_selected['y_aro_train'], lasso_aro_train_pred, \"Train\", target_range=AROUSAL_RANGE),\n",
    "    evaluate_model(data_selected['y_aro_val'], lasso_aro_val_pred, \"Validation\", target_range=AROUSAL_RANGE)\n",
    "]\n",
    "enet_aro_results = [\n",
    "    evaluate_model(data_selected['y_aro_train'], enet_aro_train_pred, \"Train\", target_range=AROUSAL_RANGE),\n",
    "    evaluate_model(data_selected['y_aro_val'], enet_aro_val_pred, \"Validation\", target_range=AROUSAL_RANGE)\n",
    "]\n",
    "svr_aro_results = [\n",
    "    evaluate_model(data_selected['y_aro_train'], svr_aro_train_pred, \"Train\", target_range=AROUSAL_RANGE),\n",
    "    evaluate_model(data_selected['y_aro_val'], svr_aro_val_pred, \"Validation\", target_range=AROUSAL_RANGE)\n",
    "]\n",
    "\n",
    "print_evaluation(ridge_aro_results, \"Ridge - Arousal\")\n",
    "print_evaluation(lasso_aro_results, \"Lasso - Arousal\")\n",
    "print_evaluation(enet_aro_results,  \"ElasticNet - Arousal\")\n",
    "print_evaluation(svr_aro_results,   \"SVR (RBF) - Arousal\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "| Metric | Formula | Interpretation | Optimal Value |\n",
    "|--------|---------|----------------|---------------|\n",
    "| **MSE** | $\\frac{1}{n}\\sum(y-\\hat{y})^2$ | Mean squared error | 0 |\n",
    "| **RMSE** | $\\sqrt{MSE}$ | Same unit as target | 0 |\n",
    "| **MAE** | $\\frac{1}{n}\\sum\\|y-\\hat{y}\\|$ | Mean absolute error | 0 |\n",
    "| **RÂ²** | $1-\\frac{SS_{res}}{SS_{tot}}$ | Explained variance ratio | 1 |\n",
    "| **NRMSE** âœ¨ | $\\frac{RMSE}{y_{max} - y_{min}}$ | Normalized RMSE | 0 |\n",
    "\n",
    "**âœ¨ NRMSE (Normalized RMSE)**\n",
    "- **Formula**: NRMSE = RMSE / (max - min)\n",
    "- **Purpose**: Provides more intuitive error interpretation (percentage of data range)\n",
    "- **Example**: If RMSE = 0.85, data range = 6.8, then NRMSE = 0.125 (12.5%)\n",
    "- **DEAM data ranges**: \n",
    "  - Valence: 1.6 - 8.4 (Î” = 6.8)\n",
    "  - Arousal: 1.6 - 8.1 (Î” = 6.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Model Evaluation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Linear Regression - Valence\n",
    "lr_val_results = [\n",
    "    evaluate_model(data_selected['y_val_train'], lr_val_train_pred, \"Train\", target_range=VALENCE_RANGE),\n",
    "    evaluate_model(data_selected['y_val_val'], lr_val_val_pred, \"Validation\", target_range=VALENCE_RANGE)\n",
    "]\n",
    "print_evaluation(lr_val_results, \"Linear Regression - Valence\")\n",
    "\n",
    "# Linear Regression - Arousal\n",
    "lr_aro_results = [\n",
    "    evaluate_model(data_selected['y_aro_train'], lr_aro_train_pred, \"Train\", target_range=AROUSAL_RANGE),\n",
    "    evaluate_model(data_selected['y_aro_val'], lr_aro_val_pred, \"Validation\", target_range=AROUSAL_RANGE)\n",
    "]\n",
    "print_evaluation(lr_aro_results, \"Linear Regression - Arousal\")\n",
    "\n",
    "# Random Forest - Valence\n",
    "rf_val_results = [\n",
    "    evaluate_model(data_all['y_val_train'], rf_val_train_pred, \"Train\", target_range=VALENCE_RANGE),\n",
    "    evaluate_model(data_all['y_val_val'], rf_val_val_pred, \"Validation\", target_range=VALENCE_RANGE)\n",
    "]\n",
    "print_evaluation(rf_val_results, \"Random Forest - Valence\")\n",
    "\n",
    "# Random Forest - Arousal\n",
    "rf_aro_results = [\n",
    "    evaluate_model(data_all['y_aro_train'], rf_aro_train_pred, \"Train\", target_range=AROUSAL_RANGE),\n",
    "    evaluate_model(data_all['y_aro_val'], rf_aro_val_pred, \"Validation\", target_range=AROUSAL_RANGE)\n",
    "]\n",
    "print_evaluation(rf_aro_results, \"Random Forest - Arousal\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Evaluation Results Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Linear Regression',\n",
    "        'Target': 'Valence',\n",
    "        'Train RÂ²': lr_val_results[0]['RÂ²'],\n",
    "        'Val RÂ²': lr_val_results[1]['RÂ²'],\n",
    "        'Val RMSE': lr_val_results[1]['RMSE'],\n",
    "        'Val NRMSE': lr_val_results[1]['NRMSE'],\n",
    "        'Val MAE': lr_val_results[1]['MAE']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Linear Regression',\n",
    "        'Target': 'Arousal',\n",
    "        'Train RÂ²': lr_aro_results[0]['RÂ²'],\n",
    "        'Val RÂ²': lr_aro_results[1]['RÂ²'],\n",
    "        'Val RMSE': lr_aro_results[1]['RMSE'],\n",
    "        'Val NRMSE': lr_aro_results[1]['NRMSE'],\n",
    "        'Val MAE': lr_aro_results[1]['MAE']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Random Forest',\n",
    "        'Target': 'Valence',\n",
    "        'Train RÂ²': rf_val_results[0]['RÂ²'],\n",
    "        'Val RÂ²': rf_val_results[1]['RÂ²'],\n",
    "        'Val RMSE': rf_val_results[1]['RMSE'],\n",
    "        'Val NRMSE': rf_val_results[1]['NRMSE'],\n",
    "        'Val MAE': rf_val_results[1]['MAE']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Random Forest',\n",
    "        'Target': 'Arousal',\n",
    "        'Train RÂ²': rf_aro_results[0]['RÂ²'],\n",
    "        'Val RÂ²': rf_aro_results[1]['RÂ²'],\n",
    "        'Val RMSE': rf_aro_results[1]['RMSE'],\n",
    "        'Val NRMSE': rf_aro_results[1]['NRMSE'],\n",
    "        'Val MAE': rf_aro_results[1]['MAE']\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Model Performance Comparison (Validation Set) - with NRMSE\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best Valence model\n",
    "valence_df = comparison_df[comparison_df['Target'] == 'Valence']\n",
    "best_val_idx = valence_df['Val RÂ²'].idxmax()\n",
    "best_val_model = valence_df.loc[best_val_idx]\n",
    "\n",
    "print(f\"\\nBest Valence model: {best_val_model['Model']}\")\n",
    "print(f\"   â€¢ RÂ² = {best_val_model['Val RÂ²']:.4f}\")\n",
    "print(f\"   â€¢ RMSE = {best_val_model['Val RMSE']:.4f}\")\n",
    "print(f\"   â€¢ NRMSE = {best_val_model['Val NRMSE']:.4f} ({best_val_model['Val NRMSE']*100:.2f}%)\")\n",
    "\n",
    "# Find best Arousal model\n",
    "arousal_df = comparison_df[comparison_df['Target'] == 'Arousal']\n",
    "best_aro_idx = arousal_df['Val RÂ²'].idxmax()\n",
    "best_aro_model = arousal_df.loc[best_aro_idx]\n",
    "\n",
    "print(f\"\\nBest Arousal model: {best_aro_model['Model']}\")\n",
    "print(f\"   â€¢ RÂ² = {best_aro_model['Val RÂ²']:.4f}\")\n",
    "print(f\"   â€¢ RMSE = {best_aro_model['Val RMSE']:.4f}\")\n",
    "print(f\"   â€¢ NRMSE = {best_aro_model['Val NRMSE']:.4f} ({best_aro_model['Val NRMSE']*100:.2f}%)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Prediction Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 True vs Predicted Scatter Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Linear Regression - Valence\n",
    "axes[0, 0].scatter(data_selected['y_val_val'], lr_val_val_pred, alpha=0.5, s=20)\n",
    "axes[0, 0].plot([1, 9], [1, 9], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('True Valence', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted Valence', fontsize=12)\n",
    "axes[0, 0].set_title(f'Linear Regression - Valence\\nRÂ² = {lr_val_results[1][\"RÂ²\"]:.4f}', fontsize=13)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Linear Regression - Arousal\n",
    "axes[0, 1].scatter(data_selected['y_aro_val'], lr_aro_val_pred, alpha=0.5, s=20, color='orange')\n",
    "axes[0, 1].plot([1, 9], [1, 9], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 1].set_xlabel('True Arousal', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Predicted Arousal', fontsize=12)\n",
    "axes[0, 1].set_title(f'Linear Regression - Arousal\\nRÂ² = {lr_aro_results[1][\"RÂ²\"]:.4f}', fontsize=13)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Random Forest - Valence\n",
    "axes[1, 0].scatter(data_all['y_val_val'], rf_val_val_pred, alpha=0.5, s=20, color='green')\n",
    "axes[1, 0].plot([1, 9], [1, 9], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1, 0].set_xlabel('True Valence', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Predicted Valence', fontsize=12)\n",
    "axes[1, 0].set_title(f'Random Forest - Valence\\nRÂ² = {rf_val_results[1][\"RÂ²\"]:.4f}', fontsize=13)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Random Forest - Arousal\n",
    "axes[1, 1].scatter(data_all['y_aro_val'], rf_aro_val_pred, alpha=0.5, s=20, color='purple')\n",
    "axes[1, 1].plot([1, 9], [1, 9], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1, 1].set_xlabel('True Arousal', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Predicted Arousal', fontsize=12)\n",
    "axes[1, 1].set_title(f'Random Forest - Arousal\\nRÂ² = {rf_aro_results[1][\"RÂ²\"]:.4f}', fontsize=13)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'prediction_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Residual Distribution\n",
    "\n",
    "Residual = True value - Predicted value\n",
    "\n",
    "Ideally, residuals should:\n",
    "- Have mean close to 0 (unbiased prediction)\n",
    "- Follow normal distribution (random errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Calculate residuals\n",
    "lr_val_residuals = data_selected['y_val_val'] - lr_val_val_pred\n",
    "lr_aro_residuals = data_selected['y_aro_val'] - lr_aro_val_pred\n",
    "rf_val_residuals = data_all['y_val_val'] - rf_val_val_pred\n",
    "rf_aro_residuals = data_all['y_aro_val'] - rf_aro_val_pred\n",
    "\n",
    "# Linear Regression - Valence\n",
    "axes[0, 0].hist(lr_val_residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 0].set_xlabel('Residuals (True - Predicted)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 0].set_title(f'LR - Valence\\nMean = {lr_val_residuals.mean():.4f}', fontsize=12)\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Linear Regression - Arousal\n",
    "axes[0, 1].hist(lr_aro_residuals, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[0, 1].axvline(0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 1].set_xlabel('Residuals (True - Predicted)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 1].set_title(f'LR - Arousal\\nMean = {lr_aro_residuals.mean():.4f}', fontsize=12)\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Random Forest - Valence\n",
    "axes[1, 0].hist(rf_val_residuals, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1, 0].axvline(0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 0].set_xlabel('Residuals (True - Predicted)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 0].set_title(f'RF - Valence\\nMean = {rf_val_residuals.mean():.4f}', fontsize=12)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Random Forest - Arousal\n",
    "axes[1, 1].hist(rf_aro_residuals, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[1, 1].axvline(0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 1].set_xlabel('Residuals (True - Predicted)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 1].set_title(f'RF - Arousal\\nMean = {rf_aro_residuals.mean():.4f}', fontsize=12)\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'residuals_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Valence-Arousal 2D Space Prediction Distribution\n",
    "\n",
    "**Purpose**: Visualize prediction distribution in Valence-Arousal 2D space to detect **\"Shortcutting\"** phenomenon.\n",
    "\n",
    "**Shortcutting phenomenon**: Model may only learn to predict a specific region (e.g., diagonal) rather than truly capturing the full emotion feature space.\n",
    "\n",
    "**Plot description**:\n",
    "- Left: True Valence-Arousal distribution (Ground Truth)\n",
    "- Right: Model-predicted Valence-Arousal distribution (Predictions)\n",
    "- Compare: Check if prediction distribution covers all regions of true distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Valence-Arousal 2D Space comparison (Linear Regression)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left: Ground Truth\n",
    "axes[0].scatter(data_selected['y_val_val'], data_selected['y_aro_val'], \n",
    "                alpha=0.6, s=30, c='blue', edgecolors='black', linewidths=0.5, label='Ground Truth')\n",
    "axes[0].set_xlabel('Valence (True)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Arousal (True)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_title('Ground Truth: Valence-Arousal Distribution', fontsize=15, fontweight='bold')\n",
    "axes[0].set_xlim(1, 9)\n",
    "axes[0].set_ylim(1, 9)\n",
    "axes[0].grid(alpha=0.3, linestyle='--')\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].axhline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0].axvline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Right: Predictions\n",
    "axes[1].scatter(lr_val_val_pred, lr_aro_val_pred, \n",
    "                alpha=0.6, s=30, c='red', edgecolors='black', linewidths=0.5, label='Predictions (LR)')\n",
    "axes[1].set_xlabel('Valence (Predicted)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Arousal (Predicted)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_title('Model Predictions: Valence-Arousal Distribution\\n(Linear Regression)', fontsize=15, fontweight='bold')\n",
    "axes[1].set_xlim(1, 9)\n",
    "axes[1].set_ylim(1, 9)\n",
    "axes[1].grid(alpha=0.3, linestyle='--')\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].axhline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1].axvline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'valence_arousal_2d_space_lr.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Valence-Arousal 2D Space comparison (Random Forest)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left: Ground Truth\n",
    "axes[0].scatter(data_all['y_val_val'], data_all['y_aro_val'], \n",
    "                alpha=0.6, s=30, c='blue', edgecolors='black', linewidths=0.5, label='Ground Truth')\n",
    "axes[0].set_xlabel('Valence (True)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Arousal (True)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_title('Ground Truth: Valence-Arousal Distribution', fontsize=15, fontweight='bold')\n",
    "axes[0].set_xlim(1, 9)\n",
    "axes[0].set_ylim(1, 9)\n",
    "axes[0].grid(alpha=0.3, linestyle='--')\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].axhline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0].axvline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Right: Predictions\n",
    "axes[1].scatter(rf_val_val_pred, rf_aro_val_pred, \n",
    "                alpha=0.6, s=30, c='green', edgecolors='black', linewidths=0.5, label='Predictions (RF)')\n",
    "axes[1].set_xlabel('Valence (Predicted)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Arousal (Predicted)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_title('Model Predictions: Valence-Arousal Distribution\\n(Random Forest)', fontsize=15, fontweight='bold')\n",
    "axes[1].set_xlim(1, 9)\n",
    "axes[1].set_ylim(1, 9)\n",
    "axes[1].grid(alpha=0.3, linestyle='--')\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].axhline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1].axvline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'valence_arousal_2d_space_rf.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Overlay comparison (Ground Truth vs Predictions)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left: Linear Regression overlay\n",
    "axes[0].scatter(data_selected['y_val_val'], data_selected['y_aro_val'], \n",
    "                alpha=0.5, s=30, c='blue', edgecolors='none', label='Ground Truth')\n",
    "axes[0].scatter(lr_val_val_pred, lr_aro_val_pred, \n",
    "                alpha=0.5, s=30, c='red', edgecolors='none', label='Predictions (LR)')\n",
    "axes[0].set_xlabel('Valence', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Arousal', fontsize=14, fontweight='bold')\n",
    "axes[0].set_title('Linear Regression: Ground Truth vs Predictions', fontsize=15, fontweight='bold')\n",
    "axes[0].set_xlim(1, 9)\n",
    "axes[0].set_ylim(1, 9)\n",
    "axes[0].grid(alpha=0.3, linestyle='--')\n",
    "axes[0].legend(fontsize=12, loc='upper left')\n",
    "axes[0].axhline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0].axvline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Right: Random Forest overlay\n",
    "axes[1].scatter(data_all['y_val_val'], data_all['y_aro_val'], \n",
    "                alpha=0.5, s=30, c='blue', edgecolors='none', label='Ground Truth')\n",
    "axes[1].scatter(rf_val_val_pred, rf_aro_val_pred, \n",
    "                alpha=0.5, s=30, c='green', edgecolors='none', label='Predictions (RF)')\n",
    "axes[1].set_xlabel('Valence', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Arousal', fontsize=14, fontweight='bold')\n",
    "axes[1].set_title('Random Forest: Ground Truth vs Predictions', fontsize=15, fontweight='bold')\n",
    "axes[1].set_xlim(1, 9)\n",
    "axes[1].set_ylim(1, 9)\n",
    "axes[1].grid(alpha=0.3, linestyle='--')\n",
    "axes[1].legend(fontsize=12, loc='upper left')\n",
    "axes[1].axhline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1].axvline(5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'valence_arousal_2d_overlay.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Valence-Arousal 2D Space Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Generated 3 plots:\")\n",
    "print(\"   1. Linear Regression: Ground Truth vs Predictions (Side-by-side)\")\n",
    "print(\"   2. Random Forest: Ground Truth vs Predictions (Side-by-side)\")\n",
    "print(\"   3. Overlay: Ground Truth vs Predictions (Both models overlaid)\")\n",
    "print(\"\\nHow to detect Shortcutting:\")\n",
    "print(\"   â€¢ If predictions concentrate on a diagonal or specific region â†’ Possible shortcutting\")\n",
    "print(\"   â€¢ If predictions cover most of the true distribution â†’ Good learning\")\n",
    "print(\"   â€¢ If predictions are too concentrated (low variance) â†’ Model may only predict mean\")\n",
    "print(\"=\" * 80)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "### Random Forest Advantage\n",
    "\n",
    "Random Forest can tell us which features are most important through the `feature_importances_` attribute.\n",
    "\n",
    "### Interpretation\n",
    "- Importance = average contribution of feature to reducing impurity\n",
    "- Higher value = more important feature\n",
    "- Sum = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get feature importances\n",
    "val_importances = pd.DataFrame({\n",
    "    'feature': feature_names_all,\n",
    "    'importance': rf_valence.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "aro_importances = pd.DataFrame({\n",
    "    'feature': feature_names_all,\n",
    "    'importance': rf_arousal.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Feature Importance Analysis (Random Forest)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nValence - TOP 10 Important Features:\")\n",
    "print(\"-\" * 60)\n",
    "for idx, row in val_importances.head(10).iterrows():\n",
    "    print(f\"  {idx+1:2d}. {row['feature']:35s} {row['importance']:.6f}\")\n",
    "\n",
    "print(\"\\nArousal - TOP 10 Important Features:\")\n",
    "print(\"-\" * 60)\n",
    "for idx, row in aro_importances.head(10).iterrows():\n",
    "    print(f\"  {idx+1:2d}. {row['feature']:35s} {row['importance']:.6f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Visualize Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Valence\n",
    "top_val = val_importances.head(15)\n",
    "axes[0].barh(range(len(top_val)), top_val['importance'], color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_val)))\n",
    "axes[0].set_yticklabels(top_val['feature'], fontsize=10)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance', fontsize=12)\n",
    "axes[0].set_title('TOP 15 Features for Valence', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Arousal\n",
    "top_aro = aro_importances.head(15)\n",
    "axes[1].barh(range(len(top_aro)), top_aro['importance'], color='coral')\n",
    "axes[1].set_yticks(range(len(top_aro)))\n",
    "axes[1].set_yticklabels(top_aro['feature'], fontsize=10)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance', fontsize=12)\n",
    "axes[1].set_title('TOP 15 Features for Arousal', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Day 4-5 Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Week 2 Day 4-5 Summary\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nCompleted tasks:\")\n",
    "print(\"  Day 4: Data preprocessing and standardization\")\n",
    "print(\"  Day 4: Data splitting (70% / 15% / 15%)\")\n",
    "print(\"  Day 4: Feature selection strategy\")\n",
    "print(\"  Day 4: Linear Regression training\")\n",
    "print(\"  Day 4: Random Forest training\")\n",
    "print(\"  Day 5: Model evaluation and comparison\")\n",
    "print(\"  Day 5: Prediction visualization\")\n",
    "print(\"  Day 5: Feature importance analysis\")\n",
    "\n",
    "print(\"\\nModel Performance Summary (Validation Set):\")\n",
    "print(\"\\n  Linear Regression:\")\n",
    "print(f\"    â€¢ Valence:  RÂ² = {lr_val_results[1]['RÂ²']:.4f}, RMSE = {lr_val_results[1]['RMSE']:.4f}\")\n",
    "print(f\"    â€¢ Arousal:  RÂ² = {lr_aro_results[1]['RÂ²']:.4f}, RMSE = {lr_aro_results[1]['RMSE']:.4f}\")\n",
    "print(f\"    â€¢ Features: {X_selected.shape[1]}\")\n",
    "\n",
    "print(\"\\n  Random Forest:\")\n",
    "print(f\"    â€¢ Valence:  RÂ² = {rf_val_results[1]['RÂ²']:.4f}, RMSE = {rf_val_results[1]['RMSE']:.4f}\")\n",
    "print(f\"    â€¢ Arousal:  RÂ² = {rf_aro_results[1]['RÂ²']:.4f}, RMSE = {rf_aro_results[1]['RMSE']:.4f}\")\n",
    "print(f\"    â€¢ Features: {X_all.shape[1]}\")\n",
    "\n",
    "print(\"\\nKey findings:\")\n",
    "valence_df = comparison_df[comparison_df['Target'] == 'Valence']\n",
    "arousal_df = comparison_df[comparison_df['Target'] == 'Arousal']\n",
    "better_val_model = valence_df.loc[valence_df['Val RÂ²'].idxmax(), 'Model']\n",
    "better_aro_model = arousal_df.loc[arousal_df['Val RÂ²'].idxmax(), 'Model']\n",
    "print(f\"  1. {better_val_model} performs better on Valence\")\n",
    "print(f\"  2. {better_aro_model} performs better on Arousal\")\n",
    "print(f\"  3. Top feature for Valence: {val_importances.iloc[0]['feature']}\")\n",
    "print(f\"  4. Top feature for Arousal: {aro_importances.iloc[0]['feature']}\")\n",
    "\n",
    "print(\"\\nOutput files:\")\n",
    "print(f\"  â€¢ models/prediction_scatter.png\")\n",
    "print(f\"  â€¢ models/residuals_distribution.png\")\n",
    "print(f\"  â€¢ models/feature_importance.png\")\n",
    "print(f\"  â€¢ models/valence_arousal_2d_space_lr.png\")\n",
    "print(f\"  â€¢ models/valence_arousal_2d_space_rf.png\")\n",
    "print(f\"  â€¢ models/valence_arousal_2d_overlay.png\")\n",
    "\n",
    "print(\"\\nNext steps (Week 3):\")\n",
    "print(\"  â†’ Hyperparameter tuning (Grid/Random Search)\")\n",
    "print(\"  â†’ Try more models (XGBoost, SVR)\")\n",
    "print(\"  â†’ Feature engineering (polynomial features)\")\n",
    "print(\"  â†’ Model ensembling\")\n",
    "print(\"  â†’ Final evaluation on test set\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Baseline model training completed!\")\n",
    "print(\"=\" * 70)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}