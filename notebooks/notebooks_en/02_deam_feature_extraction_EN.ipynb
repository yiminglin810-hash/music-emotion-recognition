{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Day 1‚Äì2: Audio Feature Extraction\n",
    "\n",
    "**Goals:**\n",
    "1. Test MFCC feature extraction\n",
    "2. Test Chroma feature extraction\n",
    "3. Test Spectral feature extraction\n",
    "4. Test Rhythm feature extraction\n",
    "5. Visualize different types of features\n",
    "\n",
    "**Dates:** November 6‚Äì7, 2025  \n",
    "**Week 2 Day 1‚Äì2 Tasks**\n",
    "\n",
    "---\n",
    "\n",
    "## Day 1: MFCC Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.features.traditional import extract_mfcc\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional: enable Chinese font support if needed in plots\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set test audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set test audio path\n",
    "# ‚ö†Ô∏è Note: DEAM song IDs are not continuous; 1.mp3 does not exist\n",
    "# Available song IDs include: [2, 3, 4, 5, 7, 8, 10, 12, 13, 17, 18, 19, 20, ...]\n",
    "test_song_id = 7  # ‚Üê use an existing song_id\n",
    "test_audio = Path(f'../data/DEAM/DEAM_audio/MEMD_audio/{test_song_id}.mp3')\n",
    "\n",
    "if test_audio.exists():\n",
    "    print(f\"Test file found: {test_audio}\")\n",
    "    print(f\"Song ID: {test_song_id}\")\n",
    "else:\n",
    "    print(f\"Test file not found: {test_audio}\")\n",
    "    print(\"Available song IDs include: 2, 3, 4, 5, 7, 8, 10, 12, 13, 17, ...\")\n",
    "    print(\"Please set test_song_id to an existing value.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract MFCC features\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract MFCC features\n",
    "mfcc_features = extract_mfcc(str(test_audio), n_mfcc=20)\n",
    "\n",
    "print(\"\\nMFCC feature shapes:\")\n",
    "print(f\"  - MFCC mean: {mfcc_features['mfcc_mean'].shape}\")\n",
    "print(f\"  - MFCC std: {mfcc_features['mfcc_std'].shape}\")\n",
    "print(f\"  - MFCC delta mean: {mfcc_features['mfcc_delta_mean'].shape}\")\n",
    "\n",
    "print(\"\\nFirst 5 MFCC mean coefficients:\")\n",
    "print(mfcc_features['mfcc_mean'][:5])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize MFCC features\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load audio\n",
    "y, sr = librosa.load(str(test_audio), sr=22050)\n",
    "print(f\"Audio duration: {len(y) / sr:.2f} seconds\")\n",
    "print(f\"Sample rate: {sr} Hz\")\n",
    "\n",
    "# Extract MFCC (for visualization)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20, hop_length=512)\n",
    "\n",
    "# Plot MFCC heatmap\n",
    "plt.figure(figsize=(14, 6))\n",
    "librosa.display.specshow(mfcc, sr=sr, x_axis='time', cmap='coolwarm', hop_length=512)\n",
    "plt.colorbar(label='MFCC value')\n",
    "plt.title(f'MFCC Feature Visualization (Song ID: {test_song_id})', fontsize=14)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('MFCC coefficients', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Day 1 sanity checks\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Day 1 sanity checks:\\n\")\n",
    "\n",
    "checks = [\n",
    "    (\"Notebook created successfully\", True),\n",
    "    (\"extract_mfcc() returns 3 feature entries\", len(mfcc_features) == 3),\n",
    "    (\"MFCC mean is 20-dimensional\", len(mfcc_features['mfcc_mean']) == 20),\n",
    "    (\"MFCC std is 20-dimensional\", len(mfcc_features['mfcc_std']) == 20),\n",
    "    (\"MFCC delta mean is 20-dimensional\", len(mfcc_features['mfcc_delta_mean']) == 20),\n",
    "    (\"MFCC heatmap rendered without error\", True),\n",
    "]\n",
    "\n",
    "for i, (description, passed) in enumerate(checks, 1):\n",
    "    status = \"OK \" if passed else \"FAIL\"\n",
    "    print(f\"[{status}] {i}. {description}\")\n",
    "\n",
    "all_passed = all(check[1] for check in checks)\n",
    "if all_passed:\n",
    "    print(\"\\nAll Day 1 checks passed.\")\n",
    "else:\n",
    "    print(\"\\nSome Day 1 checks failed. Please review.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 2: Other Feature Types\n",
    "\n",
    "### 1. Chroma feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from src.features.traditional import extract_chroma\n",
    "\n",
    "chroma_features = extract_chroma(str(test_audio))\n",
    "\n",
    "print(\"\\nChroma feature shapes:\")\n",
    "for key, value in chroma_features.items():\n",
    "    print(f\"  - {key}: {value.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize Chroma features\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract Chroma for visualization\n",
    "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=512)\n",
    "\n",
    "# Plot Chroma heatmap\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(\n",
    "    chroma_stft,\n",
    "    sr=sr,\n",
    "    x_axis='time',\n",
    "    y_axis='chroma',\n",
    "    cmap='viridis',\n",
    "    hop_length=512\n",
    ")\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.title('Chroma STFT Feature Visualization', fontsize=14)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Pitch class')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Spectral feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from src.features.traditional import extract_spectral\n",
    "\n",
    "spectral_features = extract_spectral(str(test_audio))\n",
    "\n",
    "print(\"\\nSpectral features:\")\n",
    "for key, value in spectral_features.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"  - {key}: {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  - {key}: {value:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rhythm feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from src.features.traditional import extract_rhythm\n",
    "\n",
    "rhythm_features = extract_rhythm(str(test_audio))\n",
    "\n",
    "print(\"\\nRhythm features:\")\n",
    "for key, value in rhythm_features.items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "print(f\"\\nEstimated tempo: {rhythm_features['tempo']:.1f} BPM\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Combined feature extraction test\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from src.features.traditional import extract_all_features\n",
    "\n",
    "all_features = extract_all_features(str(test_audio))\n",
    "\n",
    "print(f\"\\nExtracted {len(all_features)} aggregated features.\")\n",
    "print(\"\\nAll features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (key, value) in enumerate(all_features.items(), 1):\n",
    "    if isinstance(value, (int, float, np.floating)):\n",
    "        print(f\"{i:3d}. {key:30s}: {value:10.4f}\")\n",
    "    else:\n",
    "        print(f\"{i:3d}. {key:30s}: {value}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Day 1‚Äì2 summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Week 2 Day 1‚Äì2 Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nCompleted tasks:\")\n",
    "print(\"  1. MFCC feature extraction and visualization\")\n",
    "print(\"  2. Chroma feature extraction and visualization\")\n",
    "print(\"  3. Spectral feature extraction\")\n",
    "print(\"  4. Rhythm feature extraction\")\n",
    "print(\"  5. Combined feature extraction test\")\n",
    "\n",
    "print(\"\\nFeature dimensionality (approximate):\")\n",
    "print(\"  - MFCC: 60 dimensions (20 √ó 3)\")\n",
    "print(\"  - Chroma: 48 dimensions (12 √ó 4)\")\n",
    "print(\"  - Spectral: ~22 dimensions\")\n",
    "print(\"  - Rhythm: 3 dimensions\")\n",
    "print(f\"  - Total: {len(all_features)} aggregated dimensions\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Day 3: Batch Feature Extraction\n",
    "\n",
    "**Goals:**\n",
    "- Extract features for all 1,802 songs\n",
    "- Save features to CSV for model training\n",
    "- Verify data integrity\n",
    "\n",
    "**Estimated time:** 30‚Äì60 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import required libraries (can be skipped if previously imported)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.features.traditional import extract_all_features\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup paths and load annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set paths\n",
    "BASE_DIR = Path('..')\n",
    "AUDIO_DIR = BASE_DIR / \"data\" / \"DEAM\" / \"DEAM_audio\" / \"MEMD_audio\"\n",
    "ANNOTATION_DIR = (\n",
    "    BASE_DIR\n",
    "    / \"data\" / \"DEAM\"\n",
    "    / \"DEAM_Annotations\"\n",
    "    / \"annotations\"\n",
    "    / \"annotations averaged per song\"\n",
    "    / \"song_level\"\n",
    ")\n",
    "OUTPUT_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "# Load annotation data\n",
    "df1 = pd.read_csv(ANNOTATION_DIR / \"static_annotations_averaged_songs_1_2000.csv\")\n",
    "df2 = pd.read_csv(ANNOTATION_DIR / \"static_annotations_averaged_songs_2000_2058.csv\")\n",
    "df_annotations = pd.concat([df1, df2], ignore_index=True)\n",
    "df_annotations.columns = df_annotations.columns.str.strip()\n",
    "df_annotations = df_annotations.set_index('song_id')\n",
    "\n",
    "print(f\"Loaded {len(df_annotations)} annotations.\\n\")\n",
    "\n",
    "print(\"Path check:\")\n",
    "print(f\"  ‚Ä¢ Audio directory exists: {AUDIO_DIR.exists()}\")\n",
    "print(f\"  ‚Ä¢ Audio file count: {len(list(AUDIO_DIR.glob('*.mp3')))}\")\n",
    "print(f\"  ‚Ä¢ Output directory (will be created if missing): {OUTPUT_DIR}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test mode ‚Äì extract features for 10 songs\n",
    "\n",
    "Run on a small subset first to ensure everything works as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Test mode: extract features for 10 songs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prepare test songs\n",
    "print(\"\\nPreparing test songs...\")\n",
    "test_songs = []\n",
    "for audio_file in sorted(AUDIO_DIR.glob(\"*.mp3\"))[:15]:  # scan a bit more to skip missing ids\n",
    "    song_id = int(audio_file.stem)\n",
    "    if song_id in df_annotations.index:\n",
    "        test_songs.append(\n",
    "            {\n",
    "                'song_id': song_id,\n",
    "                'audio_path': audio_file,\n",
    "                'valence': df_annotations.loc[song_id, 'valence_mean'],\n",
    "                'arousal': df_annotations.loc[song_id, 'arousal_mean'],\n",
    "            }\n",
    "        )\n",
    "    if len(test_songs) >= 10:\n",
    "        break\n",
    "\n",
    "print(f\"Prepared {len(test_songs)} test songs.\")\n",
    "print(f\"Song IDs: {[s['song_id'] for s in test_songs]}\")\n",
    "\n",
    "# Batch extraction\n",
    "results_test = []\n",
    "failed_test = []\n",
    "\n",
    "print(\"\\nExtracting features for test songs...\\n\")\n",
    "for song_info in tqdm(test_songs, desc=\"Test extraction\", unit=\"song\"):\n",
    "    try:\n",
    "        features = extract_all_features(str(song_info['audio_path']))\n",
    "        features['song_id'] = song_info['song_id']\n",
    "        features['valence'] = song_info['valence']\n",
    "        features['arousal'] = song_info['arousal']\n",
    "        results_test.append(features)\n",
    "    except Exception as e:\n",
    "        failed_test.append({'song_id': song_info['song_id'], 'error': str(e)})\n",
    "        print(f\"\\nFailed: Song {song_info['song_id']} - {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_test = pd.DataFrame(results_test)\n",
    "cols = ['song_id', 'valence', 'arousal'] + [\n",
    "    c for c in df_test.columns if c not in ['song_id', 'valence', 'arousal']\n",
    "]\n",
    "df_test = df_test[cols]\n",
    "\n",
    "# Save test result\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "test_output = OUTPUT_DIR / \"deam_features_test.csv\"\n",
    "df_test.to_csv(test_output, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Test extraction finished.\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Successful: {len(results_test)}/{len(test_songs)}\")\n",
    "print(f\"Saved to: {test_output}\")\n",
    "print(f\"Shape: {df_test.shape}\")\n",
    "\n",
    "print(\"\\nPreview of the first 10 songs:\")\n",
    "display(\n",
    "    df_test[\n",
    "        ['song_id', 'valence', 'arousal', 'mfcc_mean_0', 'mfcc_mean_1', 'tempo']\n",
    "    ].head(10)\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Inspect overall feature structure\n",
    "print(f\"Test DataFrame shape: {df_test.shape}\")\n",
    "\n",
    "print(f\"\\nAll column names ({len(df_test.columns)} columns):\")\n",
    "print(df_test.columns.tolist())\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in df_test.columns if c not in ['song_id', 'valence', 'arousal']\n",
    "]\n",
    "print(f\"\\nNumber of feature columns: {len(feature_cols)}\")\n",
    "print(\"\\nFeature groups:\")\n",
    "print(f\"  ‚Ä¢ MFCC: {len([c for c in feature_cols if 'mfcc' in c])} dimensions\")\n",
    "print(f\"  ‚Ä¢ Chroma: {len([c for c in feature_cols if 'chroma' in c])} dimensions\")\n",
    "print(f\"  ‚Ä¢ Spectral: {len([c for c in feature_cols if 'spectral' in c])} dimensions\")\n",
    "print(\n",
    "    \"  ‚Ä¢ Rhythm: \"\n",
    "    f\"{len([c for c in feature_cols if c in ['tempo', 'beat_count', 'beat_strength', 'zcr_mean', 'zcr_std']])} \"\n",
    "    \"dimensions\"\n",
    ")\n",
    "\n",
    "print(\"\\nFull feature vector for the first song:\")\n",
    "display(df_test.iloc[0])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Full batch extraction ‚Äì all 1,802 songs\n",
    "\n",
    "‚ö†Ô∏è **Important notes:**\n",
    "- This step may take **30‚Äì60 minutes**\n",
    "- Make sure your machine does not go to sleep\n",
    "- Run only after the test mode has succeeded\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Full batch extraction ‚Äì all songs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prepare all songs\n",
    "print(\"\\nPreparing song list...\")\n",
    "all_songs = []\n",
    "for audio_file in AUDIO_DIR.glob(\"*.mp3\"):\n",
    "    song_id = int(audio_file.stem)\n",
    "    if song_id in df_annotations.index:\n",
    "        all_songs.append(\n",
    "            {\n",
    "                'song_id': song_id,\n",
    "                'audio_path': audio_file,\n",
    "                'valence': df_annotations.loc[song_id, 'valence_mean'],\n",
    "                'arousal': df_annotations.loc[song_id, 'arousal_mean'],\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"Found {len(all_songs)} valid songs.\\n\")\n",
    "\n",
    "# Batch extraction\n",
    "print(\"Extracting features for all songs...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "all_results = []\n",
    "all_failed = []\n",
    "\n",
    "for song_info in tqdm(all_songs, desc=\"Batch extraction\", unit=\"song\"):\n",
    "    try:\n",
    "        features = extract_all_features(str(song_info['audio_path']))\n",
    "        features['song_id'] = song_info['song_id']\n",
    "        features['valence'] = song_info['valence']\n",
    "        features['arousal'] = song_info['arousal']\n",
    "        all_results.append(features)\n",
    "    except Exception as e:\n",
    "        all_failed.append({'song_id': song_info['song_id'], 'error': str(e)})\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Save full result\n",
    "print(\"\\nSaving final results...\")\n",
    "df_all = pd.DataFrame(all_results)\n",
    "cols = ['song_id', 'valence', 'arousal'] + [\n",
    "    c for c in df_all.columns if c not in ['song_id', 'valence', 'arousal']\n",
    "]\n",
    "df_all = df_all[cols]\n",
    "\n",
    "final_output = OUTPUT_DIR / \"deam_features_all.csv\"\n",
    "df_all.to_csv(final_output, index=False)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Batch extraction summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total songs:      {len(all_songs)}\")\n",
    "print(f\"Successfully processed: {len(all_results)}\")\n",
    "print(f\"Failed:           {len(all_failed)}\")\n",
    "print(f\"Success rate:     {len(all_results) / len(all_songs) * 100:.1f}%\")\n",
    "print(f\"\\nElapsed time:     {elapsed / 60:.1f} minutes\")\n",
    "print(f\"Throughput:       {len(all_results) / (elapsed / 60):.1f} songs/minute\")\n",
    "print(f\"\\nOutput file:      {final_output}\")\n",
    "print(f\"Data shape:       {df_all.shape}\")\n",
    "print(f\"File size:        {final_output.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "if all_failed:\n",
    "    print(f\"\\nExamples of failed songs ({len(all_failed)} in total):\")\n",
    "    for fail in all_failed[:5]:\n",
    "        print(f\"  - Song {fail['song_id']}: {fail['error']}\")\n",
    "    if len(all_failed) > 5:\n",
    "        print(f\"  ... and {len(all_failed) - 5} more.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Validate extracted features\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the saved feature file\n",
    "output_file = OUTPUT_DIR / \"deam_features_all.csv\"\n",
    "\n",
    "if output_file.exists():\n",
    "    df_loaded = pd.read_csv(output_file)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Feature file validation\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(\"\\nFile information:\")\n",
    "    print(f\"  Path:  {output_file}\")\n",
    "    print(f\"  Size:  {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "    print(\"\\nData shape:\")\n",
    "    print(f\"  Rows (songs):       {len(df_loaded)}\")\n",
    "    print(f\"  Columns (total):    {len(df_loaded.columns)}\")\n",
    "    print(f\"  Feature dimensions: {len(df_loaded.columns) - 3} (excluding song_id, valence, arousal)\")\n",
    "\n",
    "    print(\"\\nData quality:\")\n",
    "    print(f\"  Total missing values:   {df_loaded.isnull().sum().sum()}\")\n",
    "    print(f\"  Duplicate song_ids:     {df_loaded['song_id'].duplicated().sum()}\")\n",
    "    print(\n",
    "        f\"  Valence range:          [{df_loaded['valence'].min():.2f}, {df_loaded['valence'].max():.2f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Arousal range:          [{df_loaded['arousal'].min():.2f}, {df_loaded['arousal'].max():.2f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nFeature group statistics:\")\n",
    "    feature_cols = [\n",
    "        c for c in df_loaded.columns if c not in ['song_id', 'valence', 'arousal']\n",
    "    ]\n",
    "    print(f\"  ‚Ä¢ MFCC:    {len([c for c in feature_cols if 'mfcc' in c])} dimensions\")\n",
    "    print(f\"  ‚Ä¢ Chroma:  {len([c for c in feature_cols if 'chroma' in c])} dimensions\")\n",
    "    print(f\"  ‚Ä¢ Spectral:{len([c for c in feature_cols if 'spectral' in c])} dimensions\")\n",
    "    print(\n",
    "        \"  ‚Ä¢ Rhythm:  \"\n",
    "        f\"{len([c for c in feature_cols if c in ['tempo', 'beat_count', 'beat_strength', 'zcr_mean', 'zcr_std']])} \"\n",
    "        \"dimensions\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nLabel statistics:\")\n",
    "    print(\n",
    "        f\"  Valence: Œº={df_loaded['valence'].mean():.2f}, œÉ={df_loaded['valence'].std():.2f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Arousal: Œº={df_loaded['arousal'].mean():.2f}, œÉ={df_loaded['arousal'].std():.2f}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nPreview of first 5 songs:\")\n",
    "    display(\n",
    "        df_loaded[\n",
    "            ['song_id', 'valence', 'arousal', 'mfcc_mean_0', 'tempo']\n",
    "        ].head()\n",
    "    )\n",
    "else:\n",
    "    print(\"Feature file not found. Please run the batch extraction cell first.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize feature distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if 'df_loaded' in locals():\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # 1. Valence‚ÄìArousal distribution\n",
    "    scatter = axes[0, 0].scatter(\n",
    "        df_loaded['valence'],\n",
    "        df_loaded['arousal'],\n",
    "        c=df_loaded['arousal'],\n",
    "        cmap='RdYlBu_r',\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        edgecolors='none',\n",
    "    )\n",
    "    axes[0, 0].set_xlabel('Valence', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('Arousal', fontsize=11)\n",
    "    axes[0, 0].set_title(\n",
    "        'Emotion Distribution (All 1,802 Songs)',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    axes[0, 0].axhline(5, color='gray', linestyle='--', alpha=0.3)\n",
    "    axes[0, 0].axvline(5, color='gray', linestyle='--', alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=axes[0, 0], label='Arousal')\n",
    "\n",
    "    # 2. MFCC[0] distribution (energy)\n",
    "    axes[0, 1].hist(\n",
    "        df_loaded['mfcc_mean_0'],\n",
    "        bins=50,\n",
    "        color='steelblue',\n",
    "        alpha=0.7,\n",
    "        edgecolor='black',\n",
    "    )\n",
    "    axes[0, 1].axvline(\n",
    "        df_loaded['mfcc_mean_0'].mean(),\n",
    "        color='red',\n",
    "        linestyle='--',\n",
    "        label=f\"Mean: {df_loaded['mfcc_mean_0'].mean():.1f}\",\n",
    "    )\n",
    "    axes[0, 1].set_xlabel('MFCC[0] (Energy)', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0, 1].set_title(\n",
    "        'Energy Distribution',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "    # 3. MFCC[1] distribution (timbre brightness)\n",
    "    axes[0, 2].hist(\n",
    "        df_loaded['mfcc_mean_1'],\n",
    "        bins=50,\n",
    "        color='coral',\n",
    "        alpha=0.7,\n",
    "        edgecolor='black',\n",
    "    )\n",
    "    axes[0, 2].axvline(\n",
    "        df_loaded['mfcc_mean_1'].mean(),\n",
    "        color='red',\n",
    "        linestyle='--',\n",
    "        label=f\"Mean: {df_loaded['mfcc_mean_1'].mean():.1f}\",\n",
    "    )\n",
    "    axes[0, 2].set_xlabel('MFCC[1] (Brightness)', fontsize=11)\n",
    "    axes[0, 2].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0, 2].set_title(\n",
    "        'Timbre Brightness Distribution',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(alpha=0.3, axis='y')\n",
    "\n",
    "    # 4. Tempo distribution\n",
    "    axes[1, 0].hist(\n",
    "        df_loaded['tempo'],\n",
    "        bins=50,\n",
    "        color='lightgreen',\n",
    "        alpha=0.7,\n",
    "        edgecolor='black',\n",
    "    )\n",
    "    axes[1, 0].axvline(\n",
    "        df_loaded['tempo'].mean(),\n",
    "        color='red',\n",
    "        linestyle='--',\n",
    "        label=f\"Mean: {df_loaded['tempo'].mean():.1f} BPM\",\n",
    "    )\n",
    "    axes[1, 0].set_xlabel('Tempo (BPM)', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[1, 0].set_title(\n",
    "        'Tempo Distribution',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "    # 5. Spectral centroid vs Valence\n",
    "    axes[1, 1].scatter(\n",
    "        df_loaded['spectral_centroid_mean'],\n",
    "        df_loaded['valence'],\n",
    "        alpha=0.3,\n",
    "        s=15,\n",
    "        c='purple',\n",
    "        edgecolors='none',\n",
    "    )\n",
    "    axes[1, 1].set_xlabel('Spectral Centroid (Hz)', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Valence', fontsize=11)\n",
    "    axes[1, 1].set_title(\n",
    "        'Brightness vs Valence',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "    # 6. Beat strength vs Arousal\n",
    "    axes[1, 2].scatter(\n",
    "        df_loaded['beat_strength'],\n",
    "        df_loaded['arousal'],\n",
    "        alpha=0.3,\n",
    "        s=15,\n",
    "        c='orange',\n",
    "        edgecolors='none',\n",
    "    )\n",
    "    axes[1, 2].set_xlabel('Beat Strength', fontsize=11)\n",
    "    axes[1, 2].set_ylabel('Arousal', fontsize=11)\n",
    "    axes[1, 2].set_title(\n",
    "        'Beat Strength vs Arousal',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    axes[1, 2].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Please load df_loaded first (run the validation cell).\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature correlation analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if 'df_loaded' in locals():\n",
    "    # Select key features for correlation analysis\n",
    "    key_features = [\n",
    "        'mfcc_mean_0',\n",
    "        'mfcc_mean_1',\n",
    "        'mfcc_std_0',\n",
    "        'spectral_centroid_mean',\n",
    "        'spectral_rolloff_mean',\n",
    "        'spectral_bandwidth_mean',\n",
    "        'tempo',\n",
    "        'beat_strength',\n",
    "        'zcr_mean',\n",
    "        'valence',\n",
    "        'arousal',\n",
    "    ]\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = df_loaded[key_features].corr()\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=1,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "    )\n",
    "    plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold', pad=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print top correlated features with valence and arousal\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Feature correlations with emotion labels\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\nTop correlations with Valence:\")\n",
    "    valence_corr = corr_matrix['valence'].drop('valence').sort_values(ascending=False)\n",
    "    for i, (feat, corr) in enumerate(valence_corr.head(5).items(), 1):\n",
    "        print(f\"  {i}. {feat:30s}: {corr:+.3f}\")\n",
    "\n",
    "    print(\"\\nTop correlations with Arousal:\")\n",
    "    arousal_corr = corr_matrix['arousal'].drop('arousal').sort_values(ascending=False)\n",
    "    for i, (feat, corr) in enumerate(arousal_corr.head(5).items(), 1):\n",
    "        print(f\"  {i}. {feat:30s}: {corr:+.3f}\")\n",
    "\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  ‚Ä¢ Positive correlation (> 0): higher feature value ‚Üí higher emotion value.\")\n",
    "    print(\"  ‚Ä¢ Negative correlation (< 0): higher feature value ‚Üí lower emotion value.\")\n",
    "    print(\"  ‚Ä¢ |correlation| > 0.3 is usually considered a moderate correlation.\")\n",
    "else:\n",
    "    print(\"Please load df_loaded first (run the validation cell).\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Feature Analysis Summary and Modeling Insights\n",
    "\n",
    "### üîç Key Findings\n",
    "\n",
    "#### 1Ô∏è‚É£ Feature distributions\n",
    "\n",
    "- All features show reasonable distributions with no extreme outliers.\n",
    "- Emotion labels (valence and arousal) are concentrated around the mid-range, which matches real-world music.\n",
    "- No obvious feature extraction errors were observed.\n",
    "\n",
    "#### 2Ô∏è‚É£ Multicollinearity\n",
    "\n",
    "Highly redundant feature groups:\n",
    "\n",
    "| Feature group                                      | Correlation | Note                    |\n",
    "|----------------------------------------------------|------------:|-------------------------|\n",
    "| `spectral_centroid` ‚Üî `spectral_rolloff`           |       0.98  | Almost fully redundant |\n",
    "| `spectral_centroid` ‚Üî `spectral_bandwidth`         |       0.89  | Highly correlated      |\n",
    "| `mfcc_mean_1` ‚Üî spectral features                  |      -0.90  | Strong negative link   |\n",
    "| `mfcc_mean_0` ‚Üî spectral features                  | 0.68‚Äì0.70   | Moderate correlation   |\n",
    "\n",
    "Impact:\n",
    "\n",
    "- Linear models may suffer from unstable coefficients and reduced interpretability.\n",
    "- Feature importance may be spread across redundant features.\n",
    "- Tree-based models (Random Forest, XGBoost) are less affected.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3Ô∏è‚É£ Relationship between features and emotion\n",
    "\n",
    "**Top correlations with Valence (pleasantness):**\n",
    "\n",
    "| Rank | Feature name                | Corr. | Type         |\n",
    "|------|-----------------------------|------:|--------------|\n",
    "| 1    | `mfcc_mean_0`               | +0.59 | Energy       |\n",
    "| 2    | `arousal`                   | +0.57 | Label (cross)|\n",
    "| 3    | `spectral_rolloff_mean`     | +0.55 | Spectral     |\n",
    "| 4    | `spectral_centroid_mean`    | +0.53 | Spectral     |\n",
    "| 5    | `spectral_bandwidth_mean`   | +0.51 | Spectral     |\n",
    "\n",
    "**Top correlations with Arousal (activation):**\n",
    "\n",
    "| Rank | Feature name                | Corr. | Type         |\n",
    "|------|-----------------------------|------:|--------------|\n",
    "| 1    | `mfcc_mean_0`               | +0.58 | Energy       |\n",
    "| 2    | `spectral_rolloff_mean`     | +0.57 | Spectral     |\n",
    "| 3    | `valence`                   | +0.57 | Label (cross)|\n",
    "| 4    | `spectral_centroid_mean`    | +0.55 | Spectral     |\n",
    "| 5    | `spectral_bandwidth_mean`   | +0.51 | Spectral     |\n",
    "\n",
    "**Key insights:**\n",
    "\n",
    "1. `mfcc_mean_0` is a strong global feature:\n",
    "   - Highest correlation with both valence and arousal.\n",
    "   - Represents overall energy / loudness.\n",
    "   - Should be kept in all models.\n",
    "\n",
    "2. Spectral features (`spectral_rolloff`, `spectral_centroid`, `spectral_bandwidth`):\n",
    "   - Very similar ranking and values.\n",
    "   - Confirmed redundancy ‚Üí we can keep just one representative feature.\n",
    "\n",
    "3. Valence and arousal are moderately correlated (~ +0.57):\n",
    "   - High-valence songs are often also high-arousal.\n",
    "   - Low-valence songs are often low-arousal.\n",
    "\n",
    "4. Weakly correlated but potentially useful features:\n",
    "   - `tempo` has very weak linear correlation (~0.09) but may have nonlinear effects.\n",
    "   - `beat_strength` has weak-moderate correlation (~0.22) and provides additional rhythmic information.\n",
    "\n",
    "---\n",
    "\n",
    "**Correlation magnitude interpretation:**\n",
    "\n",
    "| |corr| range | Interpretation      | Example feature             |\n",
    "|--------------|--------------------|-----------------------------|\n",
    "| 0.50‚Äì0.70    | Moderate‚Äìstrong    | `mfcc_mean_0`, spectral     |\n",
    "| 0.30‚Äì0.50    | Moderate           | `zcr_mean` (~0.40)          |\n",
    "| 0.10‚Äì0.30    | Weak               | `beat_strength` (~0.22)     |\n",
    "| < 0.10       | Very weak / none   | `tempo` (~0.09)             |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Feature selection strategies\n",
    "\n",
    "#### Strategy A: Manual feature selection (for linear models)\n",
    "\n",
    "```python\n",
    "# Keep representative, less-redundant features\n",
    "selected_features = [\n",
    "    # Energy (most important)\n",
    "    'mfcc_mean_0', 'mfcc_std_0',\n",
    "\n",
    "    # One representative spectral feature\n",
    "    'spectral_centroid_mean',\n",
    "\n",
    "    # Harmonic features (Chroma)\n",
    "    'chroma_stft_mean_*',          # 12 pitch class features\n",
    "\n",
    "    # Spectral contrast\n",
    "    'spectral_contrast_mean_*',    # 7 bands\n",
    "\n",
    "    # Rhythm features (independent information)\n",
    "    'tempo', 'beat_strength',\n",
    "\n",
    "    # Other independent features\n",
    "    'zcr_mean',\n",
    "]\n",
    "```\n",
    "\n",
    "Pros:\n",
    "- Reduces multicollinearity.\n",
    "- Improves linear model stability.\n",
    "- Speeds up training.\n",
    "\n",
    "Cons:\n",
    "- May lose some information.\n",
    "\n",
    "---\n",
    "\n",
    "#### Strategy B: PCA-based dimensionality reduction\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to highly correlated groups\n",
    "pca_spectral = PCA(n_components=1)   # spectral trio ‚Üí 1 component\n",
    "pca_mfcc = PCA(n_components=10)      # 20 MFCCs ‚Üí 10 components\n",
    "```\n",
    "\n",
    "Pros:\n",
    "- Keeps most variance.\n",
    "- Automatically handles collinearity.\n",
    "\n",
    "Cons:\n",
    "- Reduces feature interpretability.\n",
    "\n",
    "---\n",
    "\n",
    "#### Strategy C: Model-based feature importance (tree models)\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "top_indices = np.argsort(importances)[::-1][:50]\n",
    "```\n",
    "\n",
    "Pros:\n",
    "- Data-driven.\n",
    "- Captures nonlinear relationships.\n",
    "\n",
    "Cons:\n",
    "- Requires training a model first.\n",
    "\n",
    "---\n",
    "\n",
    "#### Strategy D: Keep all features (for robust nonlinear models)\n",
    "\n",
    "Tree-based models such as:\n",
    "\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "can often cope with:\n",
    "\n",
    "- Multicollinearity (by choosing splits)\n",
    "- Implicit feature selection (via importance)\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Modeling plan for Week 2 Day 4‚Äì5\n",
    "\n",
    "1. Baseline model (Linear Regression):\n",
    "   - Use Strategy A (manual selection).\n",
    "   - Remove highly collinear spectral features.\n",
    "   - Keep `spectral_centroid_mean` as representative.\n",
    "\n",
    "2. Advanced model (Random Forest):\n",
    "   - Use Strategy D (all features).\n",
    "   - Let the model learn feature importance.\n",
    "\n",
    "3. Comparative experiments:\n",
    "   - Compare performance across feature sets.\n",
    "   - Evaluate the impact of multicollinearity.\n",
    "   - Analyze feature importance rankings.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Data quality summary\n",
    "\n",
    "```\n",
    "Extracted features successfully.\n",
    "- 1,802 songs √ó ~133 feature dimensions\n",
    "- No missing values, no obvious outliers\n",
    "- Reasonable distributions for all features\n",
    "- Clear correlation with emotion labels\n",
    "- Ready for model training\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Day 3 summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Week 2 Day 1‚Äì3 Summary\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nCompleted tasks:\")\n",
    "print(\"  Day 1: MFCC feature extraction and visualization\")\n",
    "print(\"  Day 2: Chroma / Spectral / Rhythm feature extraction\")\n",
    "print(\"  Day 3: Batch feature extraction for 1,802 songs\")\n",
    "print(\"  Day 3: Saved features to CSV\")\n",
    "print(\"  Day 3: Validated data integrity\")\n",
    "print(\"  Day 3: Visualized feature distributions\")\n",
    "print(\"  Day 3: Performed feature correlation analysis\")\n",
    "\n",
    "if 'df_loaded' in locals():\n",
    "    print(\"\\nFinal dataset:\")\n",
    "    print(f\"  ‚Ä¢ Number of songs:   {len(df_loaded)}\")\n",
    "    print(f\"  ‚Ä¢ Feature dimensions:{len(df_loaded.columns) - 3}\")\n",
    "    print(f\"  ‚Ä¢ Output file:       data/processed/deam_features_all.csv\")\n",
    "    print(\n",
    "        \"  ‚Ä¢ File size:         \"\n",
    "        f\"{(OUTPUT_DIR / 'deam_features_all.csv').stat().st_size / 1024 / 1024:.2f} MB\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nFull dataset not found. Test data has been saved.\")\n",
    "\n",
    "print(\"\\nNext steps (Week 2 Day 4‚Äì5):\")\n",
    "print(\"  ‚Ä¢ Data preprocessing and train/validation split\")\n",
    "print(\"  ‚Ä¢ Train baseline regression model (Linear Regression)\")\n",
    "print(\"  ‚Ä¢ Train Random Forest model\")\n",
    "print(\"  ‚Ä¢ Evaluate and compare models\")\n",
    "print(\"  ‚Ä¢ Visualize prediction results\")\n",
    "print(\"  ‚Ä¢ Analyze feature importance\")\n",
    "\n",
    "print(\"\\nData files:\")\n",
    "print(f\"  Test subset:    {OUTPUT_DIR / 'deam_features_test.csv'}\")\n",
    "if (OUTPUT_DIR / 'deam_features_all.csv').exists():\n",
    "    print(f\"  Full dataset:   {OUTPUT_DIR / 'deam_features_all.csv'}\")\n",
    "else:\n",
    "    print(\"  Full dataset:   not generated yet.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}